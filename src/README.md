# Notebooks go here
- **Path to corpus:**`birthing_experiences/src/birth_stories_df.json.gz`: compressed json file containing the dataframe of our corpus.
- `subreddit_dfs.py`: compiles all the posts about birth stories that are 500+ words from all nine subreddits into one dataframe birth_stories_df and saves it as a compressed json file.
- `imports.py`: all the packages we use in our code and reads the json file into a dataframe.
- `corpus_stats.py`: re-implements Maria's code for Table 1 and Figure 1 (left and right): finds statistics about the corpus.
- `labeling_stories.py`: re-implements Maria's code for Table 3: assigns labels to stories based on lexicon of key words, finds number of stories assigned each label.
- `Topic_Modeling.py`: re-implements Maria's code for Figure 3: topic modeling.
- `Test_Sen.py`: re-implements Maria's code for Figure 2: sentiment analysis over the course of the narrative.
- `Personas.py`: re-implements Maria's code for Table 5: prevalence of personas in the corpus and Figure 4: distribution of personas over story time.
- `pre_post_covid.py`: separates posts made before and after March 11, 2020, when COVID-19 was declared a pandemic by WHO.
- `subreddit_stats.py`: gets statistics about number of posts made per year for all nine subreddits.
